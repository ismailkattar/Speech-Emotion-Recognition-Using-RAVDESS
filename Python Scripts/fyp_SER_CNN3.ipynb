{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 256618,
          "sourceType": "datasetVersion",
          "datasetId": 107620
        },
        {
          "sourceId": 639622,
          "sourceType": "datasetVersion",
          "datasetId": 316368
        },
        {
          "sourceId": 653195,
          "sourceType": "datasetVersion",
          "datasetId": 325566
        },
        {
          "sourceId": 671851,
          "sourceType": "datasetVersion",
          "datasetId": 338555
        },
        {
          "sourceId": 6060815,
          "sourceType": "datasetVersion",
          "datasetId": 3468263
        },
        {
          "sourceId": 8711545,
          "sourceType": "datasetVersion",
          "datasetId": 5226079
        }
      ],
      "dockerImageVersionId": 30381,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'ravdess-emotional-speech-audio:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F107620%2F256618%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T120355Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da869e00ec6147dab5812dc91e939e7aafb8f14fb62e82de201bd0599dc16ee5d8d8f88f0193dc356709271d48b988fd2c805a78d77907f280281c0a36b8cdec22037621c12ab8984309df2294d5eb0bfceaf0708a9e239056416336470dbce8af13c2a90c6bac5b02457c245626b37a2580ad24465617d549fe3ec36b05f6edf3e0bcb034f0aa4e030baf22ad82cdce7b8f57ac3b8e82bcbd562a083245a8360a2c7eab45ac8c8e9600cb294af02632b5d5c2089b50ed96de3144bdd97971dbf048970e30da734e507b3de3a3e32c386521d6293907949cd185cc2604d367ed0b7b53424d41c5005f139b89518701e0f7edbf1a85d3c819a3e4a890976ec1b95,toronto-emotional-speech-set-tess:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F316368%2F639622%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T120355Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Daa88a78b4900295de7237caa441937e352e6ef9e4c99358ce0f95c72e24915358c2fa0c6777c5253438bded14f08a81653f3fd2b333b1bda73218cc952819ce070e6c0d140c17830d9c46d250400c3074221b9ad06351fbf69fa7a4873d19029ecebdecfa9391ae59eb305e0b0740112c63d7541fbdb97d082006c4abf8b6cb3bad9f01a68a20610053a5cfa6ccd42ab8f612b942a8b40fb29690bcc4827d58e163cfb7188cb2cb233fd0fde34ee3e173668d057283fa82a728bd1d16cdd1cfd0fd09d480c601c97c1850a6545d7dfac7c40e61585241d1dd47ecc4cecc6a8b7861c49a801e314365ad9613087a2321ea7770c3a4949e91d7dd27deb2cfcd326,cremad:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F325566%2F653195%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T120355Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D25e27f8a12f3f7cf25697cc5f29b89342345ffaf4699b9c8b89bb8ba67c46851126d6e4bf838480ea7aa6a57ba9453ec7d107906c1353d64e3040622a9091a1e7798deaa5ea00a2751fee1ceeebf91acc51f82193d6d5a9c842b04e4caeb363c6cfb2d70ce4b1df93324b02cb7e7cc6e6446668f09659676d487d9edad7afd391cf08b8666ba8c1db31ea9bbe0d9cf55d3b89e181ee36803c3df56dfc5134438be622a4ec863178f72b42dcb620f8c6e7efbb708b903a7c82a97c1377f0eef905f271e79a8cb7337f68d661a477b50e92dce3ec1ddc9c7f17ab9f14ec1325dc20a6bd4bc6a5e3958f624e71e1dc3ca9ecd93aa1f42a51e26dc0ab487f9f1cb1b,surrey-audiovisual-expressed-emotion-savee:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F338555%2F671851%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T120355Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1f2e432e020cee456dd5586e473e024f644881a28cce24e512906a51ffec90f52ea9ffe08b9d8f638a8fbce56ee86aca3c518143829772cc79d954f0b2fbe251b26c0294017675a93b0976121b98381c0d179daad49097e95e22d3715dcf9e384c86dd3145393572347358c2f9be1d29c66e90a94732cae242c68d5de104a07007101a4041954992c572357fe10a5d27e69472076063768acb6d7dd956741c9e7a437d38201d10b76511c223f06bf115590f82ea562cc9be452d09c1be7413edcd85f15f2358ef3f376e1d366d6fe8d98864453839ae156b7f8da54e46c0aeea3826ef960f6ac8066c328d56e601e739c0ee57e4e5f0b6faee66fac64074ae8d,speech-signal-features:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3468263%2F6060815%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T120355Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6745d3d398fb4a708f7e88126b5685079df7945d044330d7de15d70383e41a87a28791feafb38de779ca10e8bf2b21bdb63674e710c2016579dddc75a3dbc1b0c1f8cea809a4c652ae2ba55c170dd6d8f108b9ad03dec84e8f34447f422f44c050c63e79a1f8d1ba826db63c1c6ba4438da98b1e9bc076729edd4329b59761929dd57e13f61001df18b314921560f9a5562498ba7696f9cb64dafdaca8d3450970a361a4f0f3aba7b0de877b79b21d8e426397c43aea713f3920ed05c0754a20eb9bd79971b25e7fa9031931f5dcb19f70c30f98ffa3c95f5e22cb339b74ed210f7965e2d48168ddbf2ad1f42b9838b177d253481543cc8df87aac4e6f166e33,recordedaudios:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5226079%2F8711545%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T120355Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D77001590bc3691f4080b0b68b8f229e12bbc5f5e078739a776ec891d13eecd09e2f9547d907cf1b7a2a534bb369bc3ba3517c89158d97eb92128494c1209cf1cd63831f37d07645ec4eaef58917ae7a2d26c7f283112c27a84a2378014f019e1ccd55903b520921d53da1637391448e12ca96888eb6bc891acd922ab8ccd78accffc9bf9c13298552945dcffac5702940b41dcb1e78595f636897137817330a187de2fad55ffb9ac43bc278fd446b0ce7948bad0c5313a8bcad1b384fdb8b390294e048b434361fce081034c1f3b859991229930c1d168678b624a1cb5adec6e2535405e2ab62e853710c3adac79e0e30f9d51da0b474c70e613956593194204'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "1MYX4RieFXr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27bc79af-67d2-43f7-8eab-c07213ab9ec7"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ravdess-emotional-speech-audio, 450102890 bytes compressed\n",
            "[=============================================     ] 407797760 bytes downloaded"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#IMPORT THE LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
        "import librosa\n",
        "import librosa.display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to play the audio files\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM,BatchNormalization , GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "import tensorflow as tf\n",
        "print (\"Done\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:41.694366Z",
          "iopub.execute_input": "2024-06-17T11:53:41.694871Z",
          "iopub.status.idle": "2024-06-17T11:53:48.331906Z",
          "shell.execute_reply.started": "2024-06-17T11:53:41.694768Z",
          "shell.execute_reply": "2024-06-17T11:53:48.330756Z"
        },
        "trusted": true,
        "id": "WDb0EwalFXr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libsndfile1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:48.334197Z",
          "iopub.execute_input": "2024-06-17T11:53:48.335323Z",
          "iopub.status.idle": "2024-06-17T11:53:54.742558Z",
          "shell.execute_reply.started": "2024-06-17T11:53:48.335286Z",
          "shell.execute_reply": "2024-06-17T11:53:54.741307Z"
        },
        "trusted": true,
        "id": "mDhRhQLxFXr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Data"
      ],
      "metadata": {
        "id": "XKNp2_rjFXr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                              Ravdess Dataframe\n",
        "Here is the filename identifiers as per the official RAVDESS website:\n",
        "\n",
        "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "* Vocal channel (01 = speech, 02 = song).\n",
        "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4 This means the meta data for the audio file is:\n",
        "\n",
        "* Video-only (02)\n",
        "* Speech (01)\n",
        "* Fearful (06)\n",
        "* Normal intensity (01)\n",
        "* Statement \"dogs\" (02)\n",
        "* 1st Repetition (01)\n",
        "* 12th Actor (12) - Female (as the actor ID number is even)"
      ],
      "metadata": {
        "id": "gnbwjr8LFXr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing data set\n",
        "\n",
        "ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
        "ravdess_directory_list = os.listdir(ravdess)\n",
        "print(ravdess_directory_list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:54.744234Z",
          "iopub.execute_input": "2024-06-17T11:53:54.744592Z",
          "iopub.status.idle": "2024-06-17T11:53:54.759326Z",
          "shell.execute_reply.started": "2024-06-17T11:53:54.744556Z",
          "shell.execute_reply": "2024-06-17T11:53:54.758387Z"
        },
        "trusted": true,
        "id": "1Kwby_FSFXr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing"
      ],
      "metadata": {
        "id": "TP0Ud2NXFXr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ravdees**"
      ],
      "metadata": {
        "id": "J0irazgmFXr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_emotion = []\n",
        "file_path = []\n",
        "for i in ravdess_directory_list:\n",
        "    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n",
        "    actor = os.listdir(ravdess + i)\n",
        "    for f in actor:\n",
        "        part = f.split('.')[0].split('-')\n",
        "    # third part in each file represents the emotion associated to that file.\n",
        "        file_emotion.append(int(part[2]))\n",
        "        file_path.append(ravdess + i + '/' + f)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:54.761525Z",
          "iopub.execute_input": "2024-06-17T11:53:54.761814Z",
          "iopub.status.idle": "2024-06-17T11:53:54.941596Z",
          "shell.execute_reply.started": "2024-06-17T11:53:54.761787Z",
          "shell.execute_reply": "2024-06-17T11:53:54.940849Z"
        },
        "trusted": true,
        "id": "MU415YzdFXr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(actor[0])\n",
        "print(part[0])\n",
        "print(file_path[0])\n",
        "print(int(part[2]))\n",
        "print(f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:54.942592Z",
          "iopub.execute_input": "2024-06-17T11:53:54.942848Z",
          "iopub.status.idle": "2024-06-17T11:53:54.948529Z",
          "shell.execute_reply.started": "2024-06-17T11:53:54.942823Z",
          "shell.execute_reply": "2024-06-17T11:53:54.947543Z"
        },
        "trusted": true,
        "id": "m5ItYWbpFXr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "# changing integers to actual emotions.\n",
        "ravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',\n",
        "                             8:'surprise'},\n",
        "                            inplace=True)\n",
        "print(ravdess_df.head())\n",
        "print(\"______________________________________________\")\n",
        "print(ravdess_df.tail())\n",
        "print(\"_______________________________________________\")\n",
        "print(ravdess_df.Emotions.value_counts())\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:54.950065Z",
          "iopub.execute_input": "2024-06-17T11:53:54.950679Z",
          "iopub.status.idle": "2024-06-17T11:53:54.979129Z",
          "shell.execute_reply.started": "2024-06-17T11:53:54.950649Z",
          "shell.execute_reply": "2024-06-17T11:53:54.978194Z"
        },
        "trusted": true,
        "id": "p9wy1b6LFXr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integration**"
      ],
      "metadata": {
        "id": "oQosvQznFXsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = pd.concat([ravdess_df], axis = 0)\n",
        "data_path.to_csv(\"data_path.csv\",index=False)\n",
        "data_path.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:54.980464Z",
          "iopub.execute_input": "2024-06-17T11:53:54.981062Z",
          "iopub.status.idle": "2024-06-17T11:53:55.006819Z",
          "shell.execute_reply.started": "2024-06-17T11:53:54.981024Z",
          "shell.execute_reply": "2024-06-17T11:53:55.005954Z"
        },
        "trusted": true,
        "id": "IUD206YkFXsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_path.Emotions.value_counts())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:55.007838Z",
          "iopub.execute_input": "2024-06-17T11:53:55.008124Z",
          "iopub.status.idle": "2024-06-17T11:53:55.014546Z",
          "shell.execute_reply.started": "2024-06-17T11:53:55.008097Z",
          "shell.execute_reply": "2024-06-17T11:53:55.01358Z"
        },
        "trusted": true,
        "id": "bya1d_eWFXsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">*                           Data Visualisation and Exploration"
      ],
      "metadata": {
        "id": "4TcCpwnvFXsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.title('Count of Emotions', size=16)\n",
        "sns.countplot(data_path.Emotions)\n",
        "plt.ylabel('Count', size=12)\n",
        "plt.xlabel('Emotions', size=12)\n",
        "sns.despine(top=True, right=True, left=False, bottom=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:55.015727Z",
          "iopub.execute_input": "2024-06-17T11:53:55.016062Z",
          "iopub.status.idle": "2024-06-17T11:53:55.264908Z",
          "shell.execute_reply.started": "2024-06-17T11:53:55.016035Z",
          "shell.execute_reply": "2024-06-17T11:53:55.263872Z"
        },
        "trusted": true,
        "id": "ebMIggVyFXsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data,sr = librosa.load(file_path[0])\n",
        "sr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:55.268489Z",
          "iopub.execute_input": "2024-06-17T11:53:55.268886Z",
          "iopub.status.idle": "2024-06-17T11:53:57.037251Z",
          "shell.execute_reply.started": "2024-06-17T11:53:55.268845Z",
          "shell.execute_reply": "2024-06-17T11:53:57.036186Z"
        },
        "trusted": true,
        "id": "hkSsdqkeFXsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipd.Audio(data,rate=sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:57.038705Z",
          "iopub.execute_input": "2024-06-17T11:53:57.039035Z",
          "iopub.status.idle": "2024-06-17T11:53:57.052655Z",
          "shell.execute_reply.started": "2024-06-17T11:53:57.039006Z",
          "shell.execute_reply": "2024-06-17T11:53:57.051754Z"
        },
        "trusted": true,
        "id": "1mmNZ35fFXsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Chroma STFT\n",
        "chroma_stft = librosa.feature.chroma_stft(y = data, sr=sr, n_fft=2048, hop_length=512)\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time', sr=sr, hop_length=HOP_SIZE)\n",
        "plt.colorbar()\n",
        "plt.title('Chroma STFT')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:57.053784Z",
          "iopub.execute_input": "2024-06-17T11:53:57.054092Z",
          "iopub.status.idle": "2024-06-17T11:53:57.522002Z",
          "shell.execute_reply.started": "2024-06-17T11:53:57.054058Z",
          "shell.execute_reply": "2024-06-17T11:53:57.520994Z"
        },
        "trusted": true,
        "id": "KZrTJMdDFXsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation"
      ],
      "metadata": {
        "id": "ddC3csgVFXsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOISE\n",
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "# STRETCH\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(y=data, rate=rate)\n",
        "# SHIFT\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "# PITCH\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=pitch_factor)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:57.52357Z",
          "iopub.execute_input": "2024-06-17T11:53:57.524006Z",
          "iopub.status.idle": "2024-06-17T11:53:57.533335Z",
          "shell.execute_reply.started": "2024-06-17T11:53:57.523964Z",
          "shell.execute_reply": "2024-06-17T11:53:57.532356Z"
        },
        "trusted": true,
        "id": "LJ02FiAPFXsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMAL AUDIO\n",
        "\n",
        "\n",
        "import librosa.display\n",
        "plt.figure(figsize=(12, 5))\n",
        "librosa.display.waveshow(y=data, sr=sr)\n",
        "ipd.Audio(data,rate=sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:57.534637Z",
          "iopub.execute_input": "2024-06-17T11:53:57.535086Z",
          "iopub.status.idle": "2024-06-17T11:53:57.90125Z",
          "shell.execute_reply.started": "2024-06-17T11:53:57.535055Z",
          "shell.execute_reply": "2024-06-17T11:53:57.900264Z"
        },
        "trusted": true,
        "id": "N3HV_3VZFXsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUDIO WITH NOISE\n",
        "x = noise(data)\n",
        "plt.figure(figsize=(12,5))\n",
        "librosa.display.waveshow(y=x, sr=sr)\n",
        "ipd.Audio(x, rate=sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:57.902574Z",
          "iopub.execute_input": "2024-06-17T11:53:57.902883Z",
          "iopub.status.idle": "2024-06-17T11:53:58.208183Z",
          "shell.execute_reply.started": "2024-06-17T11:53:57.902852Z",
          "shell.execute_reply": "2024-06-17T11:53:58.207166Z"
        },
        "trusted": true,
        "id": "jS3-4kg2FXsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STRETCHED AUDIO\n",
        "x = stretch(data)\n",
        "plt.figure(figsize=(12, 5))\n",
        "librosa.display.waveshow(y=x, sr=sr)\n",
        "ipd.Audio(x, rate=sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:58.209748Z",
          "iopub.execute_input": "2024-06-17T11:53:58.210661Z",
          "iopub.status.idle": "2024-06-17T11:53:58.602554Z",
          "shell.execute_reply.started": "2024-06-17T11:53:58.210611Z",
          "shell.execute_reply": "2024-06-17T11:53:58.601566Z"
        },
        "trusted": true,
        "id": "ZJuNPMvaFXsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHIFTED AUDIO\n",
        "x = shift(data)\n",
        "plt.figure(figsize=(12,5))\n",
        "librosa.display.waveshow(y=x, sr=sr)\n",
        "ipd.Audio(x, rate=sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:58.604092Z",
          "iopub.execute_input": "2024-06-17T11:53:58.604595Z",
          "iopub.status.idle": "2024-06-17T11:53:58.897843Z",
          "shell.execute_reply.started": "2024-06-17T11:53:58.604552Z",
          "shell.execute_reply": "2024-06-17T11:53:58.89688Z"
        },
        "trusted": true,
        "id": "TkUvCw3VFXsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUDIO WITH PITCH\n",
        "x = pitch(data, sr)\n",
        "plt.figure(figsize=(12, 5))\n",
        "librosa.display.waveshow(y=x, sr=sr)\n",
        "ipd.Audio(x, rate=sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:58.899405Z",
          "iopub.execute_input": "2024-06-17T11:53:58.899898Z",
          "iopub.status.idle": "2024-06-17T11:53:59.3284Z",
          "shell.execute_reply.started": "2024-06-17T11:53:58.899856Z",
          "shell.execute_reply": "2024-06-17T11:53:59.327322Z"
        },
        "trusted": true,
        "id": "qSkXkuUfFXsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction"
      ],
      "metadata": {
        "id": "VqKahAa_FXsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zcr(data,frame_length,hop_length):\n",
        "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
        "    return np.squeeze(zcr)\n",
        "def sc(data,frame_length=2048,hop_length=512):\n",
        "    sc = librosa.feature.spectral_centroid(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
        "    return np.squeeze(sc)\n",
        "def chroma_stft(data,frame_length=2048,hop_length=512,flatten:bool=True):\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
        "    return np.squeeze(chroma_stft.T)if not flatten else np.ravel(chroma_stft.T)\n",
        "\n",
        "\n",
        "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
        "    result=np.array([])\n",
        "\n",
        "    result=np.hstack((result,\n",
        "                      zcr(data,frame_length,hop_length),\n",
        "                      sc(data,frame_length,hop_length),\n",
        "                      chroma_stft(data,sr,frame_length,hop_length)\n",
        "                     ))\n",
        "    return result\n",
        "\n",
        "def get_features(path,duration=2.5, offset=0.6):\n",
        "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
        "    aud=extract_features(data)\n",
        "    audio=np.array(aud)\n",
        "\n",
        "    noised_audio=noise(data)\n",
        "    aud2=extract_features(noised_audio)\n",
        "    audio=np.vstack((audio,aud2))\n",
        "\n",
        "    pitched_audio=pitch(data,sr)\n",
        "    aud3=extract_features(pitched_audio)\n",
        "    audio=np.vstack((audio,aud3))\n",
        "\n",
        "    pitched_audio1=pitch(data,sr)\n",
        "    pitched_noised_audio=noise(pitched_audio1)\n",
        "    aud4=extract_features(pitched_noised_audio)\n",
        "    audio=np.vstack((audio,aud4))\n",
        "\n",
        "    return audio\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:59.329769Z",
          "iopub.execute_input": "2024-06-17T11:53:59.330115Z",
          "iopub.status.idle": "2024-06-17T11:53:59.344993Z",
          "shell.execute_reply.started": "2024-06-17T11:53:59.330083Z",
          "shell.execute_reply": "2024-06-17T11:53:59.343888Z"
        },
        "trusted": true,
        "id": "JHh17oCYFXsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster way to get features\n",
        "***Parallel way***\n",
        "\n",
        "**Dont be afraid from red lines that Normal**\n",
        "\n",
        "\n",
        "This code is an example of how to use the joblib library to process multiple audio files in parallel using the process_feature function. The code also uses the timeit library to measure the time taken to process the audio files.\n",
        "\n",
        "Here's a breakdown of what the code does:\n",
        "\n",
        "The from joblib import Parallel, delayed statement imports the Parallel and delayed functions from the joblib library.\n",
        "The start = timeit.default_timer() statement starts a timer to measure the time taken to process the audio files.\n",
        "The process_feature function processes a single audio file by extracting its features using the get_feat function and appending the corresponding X and Y values to the X and Y lists.\n",
        "The paths and emotions variables extract the paths and emotions from the data_path DataFrame.\n",
        "The Parallel function runs the process_feature function in parallel for each audio file using the delayed function to wrap the process_feature function.\n",
        "The results variable contains the X and Y values for each audio file.\n",
        "The X and Y lists are populated with the X and Y values from each audio file using the extend method.\n",
        "The stop = timeit.default_timer() statement stops the timer.\n",
        "The print('Time: ', stop - start) statement prints the time taken to process the audio files.\n",
        "Overall, this code demonstrates how to use the joblib library to process multiple audio files in parallel, which can significantly reduce the processing time for large datasets.This code is an example of how to use the joblib library to process multiple audio files in parallel using the process_feature function. The code also uses the timeit library to measure the time taken to process the audio files.\n",
        "\n",
        "Here's a breakdown of what the code does:\n",
        "\n",
        "The from joblib import Parallel, delayed statement imports the Parallel and delayed functions from the joblib library.\n",
        "The start = timeit.default_timer() statement starts a timer to measure the time taken to process the audio files.\n",
        "The process_feature function processes a single audio file by extracting its features using the get_feat function and appending the corresponding X and Y values to the X and Y lists.\n",
        "The paths and emotions variables extract the paths and emotions from the data_path DataFrame.\n",
        "The Parallel function runs the process_feature function in parallel for each audio file using the delayed function to wrap the process_feature function.\n",
        "The results variable contains the X and Y values for each audio file.\n",
        "The X and Y lists are populated with the X and Y values from each audio file using the extend method.\n",
        "The stop = timeit.default_timer() statement stops the timer.\n",
        "The print('Time: ', stop - start) statement prints the time taken to process the audio files.\n",
        "Overall, this code demonstrates how to use the joblib library to process multiple audio files in parallel, which can significantly reduce the processing time for large datasets."
      ],
      "metadata": {
        "id": "2nWegHBeFXsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  The .extend() method increases the length of the list by the number of elements that are provided to the method, so if you want to add multiple elements to the list, you can use this method."
      ],
      "metadata": {
        "id": "pNC-Nkz8FXsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import Parallel, delayed\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "# Define a function to get features for a single audio file\n",
        "def process_feature(path, emotion):\n",
        "    features = get_features(path)\n",
        "    X = []\n",
        "    Y = []\n",
        "    for ele in features:\n",
        "        X.append(ele)\n",
        "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
        "        Y.append(emotion)\n",
        "    return X, Y\n",
        "\n",
        "paths = data_path.Path\n",
        "emotions = data_path.Emotions\n",
        "\n",
        "# Run the loop in parallel\n",
        "results = Parallel(n_jobs=-1)(delayed(process_feature)(path, emotion) for (path, emotion) in zip(paths, emotions))\n",
        "\n",
        "# Collect the results\n",
        "X = []\n",
        "Y = []\n",
        "for result in results:\n",
        "    x, y = result\n",
        "    X.extend(x)\n",
        "    Y.extend(y)\n",
        "\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "\n",
        "print('Time: ', stop - start)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:53:59.34613Z",
          "iopub.execute_input": "2024-06-17T11:53:59.346441Z",
          "iopub.status.idle": "2024-06-17T11:58:53.555122Z",
          "shell.execute_reply.started": "2024-06-17T11:53:59.346412Z",
          "shell.execute_reply": "2024-06-17T11:58:53.55378Z"
        },
        "trusted": true,
        "id": "1V89gX45FXsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(Y), data_path.Path.shape\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:58:53.556675Z",
          "iopub.execute_input": "2024-06-17T11:58:53.557047Z",
          "iopub.status.idle": "2024-06-17T11:58:53.564773Z",
          "shell.execute_reply.started": "2024-06-17T11:58:53.55701Z",
          "shell.execute_reply": "2024-06-17T11:58:53.56376Z"
        },
        "trusted": true,
        "id": "buTrHUVRFXsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving features"
      ],
      "metadata": {
        "id": "Joys84pTFXsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Emotions = pd.DataFrame(X)\n",
        "Emotions['Emotions'] = Y\n",
        "Emotions.to_csv('emotion.csv', index=False)\n",
        "Emotions.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T12:00:41.589861Z",
          "iopub.execute_input": "2024-06-17T12:00:41.5903Z",
          "iopub.status.idle": "2024-06-17T12:00:41.607799Z",
          "shell.execute_reply.started": "2024-06-17T12:00:41.590264Z",
          "shell.execute_reply": "2024-06-17T12:00:41.606506Z"
        },
        "trusted": true,
        "id": "7mnC0IlFFXsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Emotions = pd.read_csv('./emotion.csv')\n",
        "Emotions.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PIJoVnsGFXsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Emotions.isna().any())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZzY0OsemFXsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Emotions=Emotions.fillna(0)\n",
        "print(Emotions.isna().any())\n",
        "Emotions.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "6N4JcC7LFXsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(Emotions.isna())"
      ],
      "metadata": {
        "trusted": true,
        "id": "LIzPZnSwFXsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "FAABr0mdFXsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#taking all rows and all cols without last col for X which include features\n",
        "#taking last col for Y, which include the emotions\n",
        "\n",
        "\n",
        "X = Emotions.iloc[: ,:-1].values\n",
        "Y = Emotions['Emotions'].values"
      ],
      "metadata": {
        "trusted": true,
        "id": "9gwh78SlFXsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As this is a multiclass classification problem onehotencoding our Y\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "B86rkHbRFXsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y.shape)\n",
        "X.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "cVDuxAxJFXsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42,test_size=0.2, shuffle=True)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZkCI0X6mFXsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape for lstm\n",
        "X_train = x_train.reshape(x_train.shape[0] , x_train.shape[1] , 1)\n",
        "X_test = x_test.reshape(x_test.shape[0] , x_test.shape[1] , 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "D3JGLtDaFXsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling our data with sklearn's Standard scaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ei5VxHr5FXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM,BatchNormalization , GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "trusted": true,
        "id": "kKKwwivRFXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Applying early stopping for all models\n"
      ],
      "metadata": {
        "id": "2mjbkfDDFXsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
        "model_checkpoint = ModelCheckpoint('best_model1_weights.h5', monitor='val_accuracy', save_best_only=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "NJxsCmaTFXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stop=EarlyStopping(monitor='val_accuracy',mode='auto',patience=10,restore_best_weights=True)\n",
        "lr_reduction=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
      ],
      "metadata": {
        "trusted": true,
        "id": "LOCJ3SpEFXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN model"
      ],
      "metadata": {
        "id": "wQwBsNu4FXsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape for CNN_LSTM MODEL\n",
        "\n",
        "x_traincnn =np.expand_dims(x_train, axis=2)\n",
        "x_testcnn= np.expand_dims(x_test, axis=2)\n",
        "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape\n",
        "#x_testcnn[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZofWCfZlFXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.layers as L\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    L.Conv1D(512,kernel_size=5, strides=1,padding='same', activation='relu',input_shape=(X_train.shape[1],1)),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "\n",
        "    L.Conv1D(512,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "    Dropout(0.2),  # Add dropout layer after the second max pooling layer\n",
        "\n",
        "    L.Conv1D(256,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "\n",
        "    L.Conv1D(256,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "    Dropout(0.2),  # Add dropout layer after the fourth max pooling layer\n",
        "\n",
        "    L.Conv1D(128,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=3,strides=2,padding='same'),\n",
        "    Dropout(0.2),  # Add dropout layer after the fifth max pooling layer\n",
        "\n",
        "    L.Flatten(),\n",
        "    L.Dense(512,activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.Dense(7,activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mv7Rh4VuFXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x_traincnn, y_train, epochs=50, validation_data=(x_testcnn, y_test), batch_size=64,callbacks=[early_stop,lr_reduction,model_checkpoint])"
      ],
      "metadata": {
        "trusted": true,
        "id": "orqn2QrGFXsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")\n",
        "\n",
        "epochs = [i for i in range(50)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "test_acc = history.history['val_accuracy']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "fig.set_size_inches(20,6)\n",
        "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
        "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
        "ax[0].set_title('Training & Testing Loss')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
        "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
        "ax[1].set_title('Training & Testing Accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_clUYypAFXsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting on test data.\n",
        "pred_test0 = model.predict(x_testcnn)\n",
        "y_pred0 = encoder.inverse_transform(pred_test0)\n",
        "y_test0 = encoder.inverse_transform(y_test)\n",
        "\n",
        "# Check for random predictions\n",
        "df0 = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
        "df0['Predicted Labels'] = y_pred0.flatten()\n",
        "df0['Actual Labels'] = y_test0.flatten()\n",
        "\n",
        "df0.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ftuCtyJXFXsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df0"
      ],
      "metadata": {
        "trusted": true,
        "id": "OQqiOmJDFXsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalutation"
      ],
      "metadata": {
        "id": "egshOag6FXsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results of best model"
      ],
      "metadata": {
        "id": "6vg6PR59FXsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test0, y_pred0)\n",
        "plt.figure(figsize = (12, 10))\n",
        "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
        "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='.2f')\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Labels', size=14)\n",
        "plt.ylabel('Actual Labels', size=14)\n",
        "plt.show()\n",
        "print(classification_report(y_test0, y_pred0))"
      ],
      "metadata": {
        "trusted": true,
        "id": "eFgw8bXmFXsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Best Model"
      ],
      "metadata": {
        "id": "Iz-3mdCZFXsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"CNN_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"CNN_model_weights.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "tfcBk_xrFXsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "json_file = open('CNN_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"best_model1_weights.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-Z_jT_H_FXsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(x_testcnn,y_test)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "metadata": {
        "trusted": true,
        "id": "bFOoXSBmFXsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading our Stnadrad Scaler and encoder\n",
        "* To save the StandardScaler object to use it later in a Flask API"
      ],
      "metadata": {
        "id": "M6d6x6bmFXsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pickle file\n"
      ],
      "metadata": {
        "id": "cziKdDlQFXsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Saving scaler\n",
        "with open('scaler2.pickle', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "# Loading scaler\n",
        "with open('scaler2.pickle', 'rb') as f:\n",
        "    scaler2 = pickle.load(f)\n",
        "\n",
        "# Saving encoder\n",
        "with open('encoder2.pickle', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n",
        "\n",
        "# Loading encoder\n",
        "with open('encoder2.pickle', 'rb') as f:\n",
        "    encoder2 = pickle.load(f)\n",
        "\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "AgMhBU5tFXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test script\n",
        "* That can predict new record"
      ],
      "metadata": {
        "id": "Wm5so8HIFXsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "json_file = open('CNN_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"best_model1_weights.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "6CFgeWqrFXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('scaler2.pickle', 'rb') as f:\n",
        "    scaler2 = pickle.load(f)\n",
        "\n",
        "with open('encoder2.pickle', 'rb') as f:\n",
        "    encoder2 = pickle.load(f)\n",
        "\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "kVaRdoiYFXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "trusted": true,
        "id": "t4fJMXDYFXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zcr(data,frame_length,hop_length):\n",
        "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
        "    return np.squeeze(zcr)\n",
        "def sc(data,frame_length=2048,hop_length=512):\n",
        "    sc = librosa.feature.spectral_centroid(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
        "    return np.squeeze(sc)\n",
        "def chroma_stft(data,frame_length=2048,hop_length=512,flatten:bool=True):\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
        "    return np.squeeze(chroma_stft.T)if not flatten else np.ravel(chroma_stft.T)\n",
        "\n",
        "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
        "    result=np.array([])\n",
        "\n",
        "    result=np.hstack((result,\n",
        "                      zcr(data,frame_length,hop_length),\n",
        "                      sc(data,frame_length,hop_length),\n",
        "                      chroma_stft(data,frame_length,hop_length)\n",
        "                     ))\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "id": "BpDj-me6FXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predict_feat(path):\n",
        "    d, s_rate= librosa.load(path, duration=2.5, offset=0.6)\n",
        "    res=extract_features(d)\n",
        "    result=np.array(res)\n",
        "    result=np.reshape(result,newshape=(1,2376))\n",
        "    i_result = scaler2.transform(result)\n",
        "    final_result=np.expand_dims(i_result, axis=2)\n",
        "\n",
        "    return final_result"
      ],
      "metadata": {
        "trusted": true,
        "id": "J58efjQiFXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=get_predict_feat(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")\n",
        "print(res.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IRSi3zO4FXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions1={1:'Neutral', 2:'Calm', 3:'Happy', 4:'Sad', 5:'Angry', 6:'Fear', 7:'Disgust',8:'Surprise'}\n",
        "def prediction(path1):\n",
        "    res=get_predict_feat(path1)\n",
        "    predictions=loaded_model.predict(res)\n",
        "    y_pred = encoder2.inverse_transform(predictions)\n",
        "    print(y_pred[0][0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "SWeyxZPUFXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-01-01-01-01-02.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "DwJjL2CsFXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-01-01-01-01-01.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "neqn7CxLFXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-05-01-02-02-01.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "FhcPBkxaFXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_21/03-01-04-02-02-02-21.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "uY5LTQzpFXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-06-01-02-02-02.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "XHRKPa_qFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-08-01-01-01-01.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "oPn0kOiMFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fS8RqeedFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/recordedaudios/wav/A angry vanessa hajj catherine.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "xDVA_Mu9FXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/recordedaudios/wav/F willy happy1.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MbXCpAEmFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/recordedaudios/wav/E willy angry.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "2kBFuNYmFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/recordedaudios/wav/E ralph abou merhi sad.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "9DixHFbAFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/recordedaudios/wav/E mariane fearful.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "OypgUP_PFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"/kaggle/input/recordedaudios/wav/A mariane disgust-2.wav\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "yRbehybPFXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vCGrklGFXsO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}